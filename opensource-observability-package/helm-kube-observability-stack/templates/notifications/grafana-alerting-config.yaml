{{- if .Values.notifications.grafana_alerting.enabled }}
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-alerting-provisioning
  namespace: {{ .Values.namespace }}
data:
  # Grafana Alerting Contact Points Configuration
  contactpoints.yaml: |
    apiVersion: 1
    contactPoints:

{{- if .Values.notifications.servicenow.enabled }}
    # ServiceNow Webhook Contact Point
    - orgId: 1
      name: servicenow-webhook
      receivers:
      - uid: servicenow-webhook-uid
        type: webhook
        settings:
          url: http://{{ .Values.notifications.node_ip }}:30950/create-incident
          httpMethod: POST
          username: {{ .Values.notifications.servicenow.username }}
          password: {{ .Values.notifications.servicenow.password }}
          title: "Critical Alert: {{ "{{ $labels.alertname }}" }}"
          message: |
            {
              "alert_name": "{{ "{{ $labels.alertname }}" }}",
              "summary": "{{ "{{ $annotations.summary }}" }}",
              "description": "{{ "{{ $annotations.description }}" }}",
              "instance": "{{ "{{ $labels.instance }}" }}",
              "namespace": "{{ "{{ $labels.namespace }}" }}",
              "severity": "{{ "{{ $labels.severity }}" }}",
              "started_at": "{{ "{{ $labels.__alert_time__ }}" }}",
              "grafana_url": "http://{{ .Values.notifications.node_ip }}:30300"
            }
{{- end }}

{{- if .Values.notifications.webex.enabled }}
    # WebEx Teams Webhook Contact Point
    - orgId: 1
      name: webex-webhook
      receivers:
      - uid: webex-webhook-uid
        type: webhook
        settings:
          url: http://{{ .Values.notifications.node_ip }}:30951/webex-webhook
          httpMethod: POST
          title: "{{ "{{ $labels.severity | upper }}" }}: {{ "{{ $labels.alertname }}" }}"
          message: |
            {
              "alert_name": "{{ "{{ $labels.alertname }}" }}",
              "summary": "{{ "{{ $annotations.summary }}" }}",
              "description": "{{ "{{ $annotations.description }}" }}",
              "instance": "{{ "{{ $labels.instance }}" }}",
              "namespace": "{{ "{{ $labels.namespace }}" }}",
              "severity": "{{ "{{ $labels.severity }}" }}",
              "started_at": "{{ "{{ $labels.__alert_time__ }}" }}"
            }
{{- end }}

  # Grafana Notification Policies Configuration
  policies.yaml: |
    apiVersion: 1
    policies:
    - orgId: 1
      receiver: {{- if .Values.notifications.webex.enabled }} webex-webhook {{- else if .Values.notifications.servicenow.enabled }} servicenow-webhook {{- else }} default-receiver {{- end }}
      group_by: ['alertname', 'namespace']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 4h

      routes:
{{- if .Values.notifications.servicenow.enabled }}
      # Critical alerts: ServiceNow + WebEx (if enabled)
      - matchers:
        - severity = critical
        receiver: servicenow-webhook
{{- if .Values.notifications.webex.enabled }}
        continue: true
        routes:
        - receiver: webex-webhook
{{- end }}
        group_wait: 10s
        repeat_interval: 1h
{{- else if .Values.notifications.webex.enabled }}
      # Critical alerts: WebEx only
      - matchers:
        - severity = critical
        receiver: webex-webhook
        group_wait: 10s
        repeat_interval: 1h
{{- end }}

{{- if .Values.notifications.webex.enabled }}
      # Warning alerts: WebEx only (no ServiceNow incidents for warnings)
      - matchers:
        - severity = warning
        receiver: webex-webhook
        repeat_interval: 2h
{{- end }}

---
# Grafana Alerting Rules Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-alert-rules
  namespace: {{ .Values.namespace }}
data:
  rules.yaml: |
    apiVersion: 1
    groups:
    - orgId: 1
      name: basic-alerts
      folder: Basic Monitoring
      interval: 1m
      rules:
      # Simple Node Down Alert
      - uid: node-down-simple
        title: Node Down
        condition: A
        data:
        - refId: A
          queryType: ''
          relativeTimeRange:
            from: 300
            to: 0
          datasource:
            type: prometheus
            uid: prometheus
          model:
            expr: up{job="node-exporter"} == 0
            refId: A
        noDataState: NoData
        execErrState: Alerting
        for: 2m
        annotations:
          summary: "Node is down"
          description: "Node {{ "{{ $labels.instance }}" }} has been down for more than 2 minutes"
        labels:
          severity: critical

      # Simple Prometheus Down Alert
      - uid: prometheus-down-simple
        title: Prometheus Down
        condition: A
        data:
        - refId: A
          queryType: ''
          relativeTimeRange:
            from: 300
            to: 0
          datasource:
            type: prometheus
            uid: prometheus
          model:
            expr: up{job="prometheus"} == 0
            refId: A
        noDataState: NoData
        execErrState: Alerting
        for: 1m
        annotations:
          summary: "Prometheus is down"
          description: "Prometheus server is not responding"
        labels:
          severity: critical

      # Simple High CPU Alert
      - uid: high-cpu-simple
        title: High CPU Usage
        condition: A
        data:
        - refId: A
          queryType: ''
          relativeTimeRange:
            from: 600
            to: 0
          datasource:
            type: prometheus
            uid: prometheus
          model:
            expr: (100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)) > 80
            refId: A
        noDataState: NoData
        execErrState: Alerting
        for: 5m
        annotations:
          summary: "High CPU usage detected"
          description: "CPU usage is above 80% on {{ "{{ $labels.instance }}" }}"
        labels:
          severity: warning
{{- end }}